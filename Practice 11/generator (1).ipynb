{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "99tV4nXuqEVg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3l0Tedl5qEVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f135cd46-8396-4498-8ede-6ac07615af5b"
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gRsvPDiUqEWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXDo6DljqMsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "33d8a93d-8c1d-4086-d88e-a4579c74a5be"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZjPj8NvqfjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/pr-11\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RB4v-TcxqtX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ccbccf1-326b-4572-a321-d922804789f2"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generator.ipynb  train_cars\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NvscOC32qEW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = string.punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uPeYwVjbqEXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = chars.replace(\"'\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yjQE5htEqEXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c0babf1-99e6-4129-e075-2bd02a23e0f3"
      },
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "taRvAA-qqEXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = chars.replace(\"`\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzgdaJBRqEXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"alice_in_wonderland.txt\", \"r\")\n",
        "alice = f.read()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9oc34wPBqEXs",
        "colab_type": "code",
        "colab": {},
        "outputId": "23dae2c4-3431-4b53-a411-3e432dc3143f"
      },
      "cell_type": "code",
      "source": [
        "len(alice)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "xeJ3jQnfqEX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\" '\", '\"')\n",
        "alice = alice.replace(\"' \", '\"')\n",
        "alice = alice.replace(\" `\", '\"')\n",
        "alice = alice.replace(\"` \", '\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBVhReD6qEX7",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5753a34-7062-489f-8da7-35f5bca2f20b"
      },
      "cell_type": "code",
      "source": [
        "print(alice[:1500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice's Adventures in Wonderland\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "                      Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "  Alice was beginning to get very tired of sitting by her sister\n",
            "on the bank, and of having nothing to do:  once or twice she had\n",
            "peeped into the book her sister was reading, but it had no\n",
            "pictures or conversations in it,\"and what is the use of a book,'\n",
            "thought Alice\"without pictures or conversation?'\n",
            "\n",
            "  So she was considering in her own mind (as well as she could,\n",
            "for the hot day made her feel very sleepy and stupid), whether\n",
            "the pleasure of making a daisy-chain would be worth the trouble\n",
            "of getting up and picking the daisies, when suddenly a White\n",
            "Rabbit with pink eyes ran close by her.\n",
            "\n",
            "  There was nothing so VERY remarkable in that; nor did Alice\n",
            "think it so VERY much out of the way to hear the Rabbit say to\n",
            "itself,\"Oh dear!  Oh dear!  I shall be late!\" (when she thought\n",
            "it over afterwards, it occurred to her that she ought to have\n",
            "wondered at this, but at the time it all seemed quite natural);\n",
            "but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-\n",
            "POCKET, and looked at it, and then hurried on, Alice started to\n",
            "her feet, for it flashed across her mind that she had never\n",
            "before seen a rabbit with either a waistcoat-pocket, or a watch to\n",
            "take out of it, and burning with curiosity, she ran across the\n",
            "field a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K1u5ADDzqEYB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk5gbaQmqEYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s=\"\\n\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jT-I1ewhqEYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s = re.sub(\"\\n\\n+\", \"a\", s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hi-J071JqEYN",
        "colab_type": "code",
        "colab": {},
        "outputId": "f6cf86d9-25f2-40f6-8b09-12fe77c8fd71"
      },
      "cell_type": "code",
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "-sTLVwDIqEYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = re.sub(\"\\n\\n+\", \"qwerty\", alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZppX7ReDqEYi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\"\\n\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRwyff39qEYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\"qwerty\", \" \\n \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLN-n6IxqEYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\" '\", '\"')\n",
        "alice = alice.replace(\"' \", '\"')\n",
        "alice = alice.replace(\" `\", '\"')\n",
        "alice = alice.replace(\"` \", '\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kj7RGSkeqEY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for c in chars:\n",
        "    alice = alice.replace(c, \" \"+c+\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9MfBly4qEY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\"\\t\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rqaKtTbiqEZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.replace(\"*\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pES9sHiJqEZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"alice_formatted.txt\", \"w\")\n",
        "f.write(alice)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWOtbXZsqEZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"alice_formatted.txt\", \"r\")\n",
        "alice = f.read()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "javEHG5KqEZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice = alice.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "07kxXJLFqEZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice_words = alice.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEG6qGI7qEZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18217
        },
        "outputId": "45988572-915c-4bbd-b5c1-fe8146020094"
      },
      "cell_type": "code",
      "source": [
        "alice_words"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"alice's\",\n",
              " 'adventures',\n",
              " 'in',\n",
              " 'wonderland',\n",
              " \"alice's\",\n",
              " 'adventures',\n",
              " 'in',\n",
              " 'wonderland',\n",
              " 'lewis',\n",
              " 'carroll',\n",
              " 'the',\n",
              " 'millennium',\n",
              " 'fulcrum',\n",
              " 'edition',\n",
              " '3',\n",
              " '.',\n",
              " '0',\n",
              " 'chapter',\n",
              " 'i',\n",
              " 'down',\n",
              " 'the',\n",
              " 'rabbit',\n",
              " '-',\n",
              " 'hole',\n",
              " 'alice',\n",
              " 'was',\n",
              " 'beginning',\n",
              " 'to',\n",
              " 'get',\n",
              " 'very',\n",
              " 'tired',\n",
              " 'of',\n",
              " 'sitting',\n",
              " 'by',\n",
              " 'her',\n",
              " 'sister',\n",
              " 'on',\n",
              " 'the',\n",
              " 'bank',\n",
              " ',',\n",
              " 'and',\n",
              " 'of',\n",
              " 'having',\n",
              " 'nothing',\n",
              " 'to',\n",
              " 'do',\n",
              " ':',\n",
              " 'once',\n",
              " 'or',\n",
              " 'twice',\n",
              " 'she',\n",
              " 'had',\n",
              " 'peeped',\n",
              " 'into',\n",
              " 'the',\n",
              " 'book',\n",
              " 'her',\n",
              " 'sister',\n",
              " 'was',\n",
              " 'reading',\n",
              " ',',\n",
              " 'but',\n",
              " 'it',\n",
              " 'had',\n",
              " 'no',\n",
              " 'pictures',\n",
              " 'or',\n",
              " 'conversations',\n",
              " 'in',\n",
              " 'it',\n",
              " ',',\n",
              " '\"',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'a',\n",
              " 'book',\n",
              " ',',\n",
              " '\"',\n",
              " 'thought',\n",
              " 'alice',\n",
              " '\"',\n",
              " 'without',\n",
              " 'pictures',\n",
              " 'or',\n",
              " 'conversation',\n",
              " '?',\n",
              " '\"',\n",
              " 'so',\n",
              " 'she',\n",
              " 'was',\n",
              " 'considering',\n",
              " 'in',\n",
              " 'her',\n",
              " 'own',\n",
              " 'mind',\n",
              " '(',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'she',\n",
              " 'could',\n",
              " ',',\n",
              " 'for',\n",
              " 'the',\n",
              " 'hot',\n",
              " 'day',\n",
              " 'made',\n",
              " 'her',\n",
              " 'feel',\n",
              " 'very',\n",
              " 'sleepy',\n",
              " 'and',\n",
              " 'stupid',\n",
              " ')',\n",
              " ',',\n",
              " 'whether',\n",
              " 'the',\n",
              " 'pleasure',\n",
              " 'of',\n",
              " 'making',\n",
              " 'a',\n",
              " 'daisy',\n",
              " '-',\n",
              " 'chain',\n",
              " 'would',\n",
              " 'be',\n",
              " 'worth',\n",
              " 'the',\n",
              " 'trouble',\n",
              " 'of',\n",
              " 'getting',\n",
              " 'up',\n",
              " 'and',\n",
              " 'picking',\n",
              " 'the',\n",
              " 'daisies',\n",
              " ',',\n",
              " 'when',\n",
              " 'suddenly',\n",
              " 'a',\n",
              " 'white',\n",
              " 'rabbit',\n",
              " 'with',\n",
              " 'pink',\n",
              " 'eyes',\n",
              " 'ran',\n",
              " 'close',\n",
              " 'by',\n",
              " 'her',\n",
              " '.',\n",
              " 'there',\n",
              " 'was',\n",
              " 'nothing',\n",
              " 'so',\n",
              " 'very',\n",
              " 'remarkable',\n",
              " 'in',\n",
              " 'that',\n",
              " ';',\n",
              " 'nor',\n",
              " 'did',\n",
              " 'alice',\n",
              " 'think',\n",
              " 'it',\n",
              " 'so',\n",
              " 'very',\n",
              " 'much',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'way',\n",
              " 'to',\n",
              " 'hear',\n",
              " 'the',\n",
              " 'rabbit',\n",
              " 'say',\n",
              " 'to',\n",
              " 'itself',\n",
              " ',',\n",
              " '\"',\n",
              " 'oh',\n",
              " 'dear',\n",
              " '!',\n",
              " 'oh',\n",
              " 'dear',\n",
              " '!',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'be',\n",
              " 'late',\n",
              " '!',\n",
              " '\"',\n",
              " '(',\n",
              " 'when',\n",
              " 'she',\n",
              " 'thought',\n",
              " 'it',\n",
              " 'over',\n",
              " 'afterwards',\n",
              " ',',\n",
              " 'it',\n",
              " 'occurred',\n",
              " 'to',\n",
              " 'her',\n",
              " 'that',\n",
              " 'she',\n",
              " 'ought',\n",
              " 'to',\n",
              " 'have',\n",
              " 'wondered',\n",
              " 'at',\n",
              " 'this',\n",
              " ',',\n",
              " 'but',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " 'it',\n",
              " 'all',\n",
              " 'seemed',\n",
              " 'quite',\n",
              " 'natural',\n",
              " ')',\n",
              " ';',\n",
              " 'but',\n",
              " 'when',\n",
              " 'the',\n",
              " 'rabbit',\n",
              " 'actually',\n",
              " 'took',\n",
              " 'a',\n",
              " 'watch',\n",
              " 'out',\n",
              " 'of',\n",
              " 'its',\n",
              " 'waistcoat',\n",
              " '-',\n",
              " 'pocket',\n",
              " ',',\n",
              " 'and',\n",
              " 'looked',\n",
              " 'at',\n",
              " 'it',\n",
              " ',',\n",
              " 'and',\n",
              " 'then',\n",
              " 'hurried',\n",
              " 'on',\n",
              " ',',\n",
              " 'alice',\n",
              " 'started',\n",
              " 'to',\n",
              " 'her',\n",
              " 'feet',\n",
              " ',',\n",
              " 'for',\n",
              " 'it',\n",
              " 'flashed',\n",
              " 'across',\n",
              " 'her',\n",
              " 'mind',\n",
              " 'that',\n",
              " 'she',\n",
              " 'had',\n",
              " 'never',\n",
              " 'before',\n",
              " 'seen',\n",
              " 'a',\n",
              " 'rabbit',\n",
              " 'with',\n",
              " 'either',\n",
              " 'a',\n",
              " 'waistcoat',\n",
              " '-',\n",
              " 'pocket',\n",
              " ',',\n",
              " 'or',\n",
              " 'a',\n",
              " 'watch',\n",
              " 'to',\n",
              " 'take',\n",
              " 'out',\n",
              " 'of',\n",
              " 'it',\n",
              " ',',\n",
              " 'and',\n",
              " 'burning',\n",
              " 'with',\n",
              " 'curiosity',\n",
              " ',',\n",
              " 'she',\n",
              " 'ran',\n",
              " 'across',\n",
              " 'the',\n",
              " 'field',\n",
              " 'after',\n",
              " 'it',\n",
              " ',',\n",
              " 'and',\n",
              " 'fortunately',\n",
              " 'was',\n",
              " 'just',\n",
              " 'in',\n",
              " 'time',\n",
              " 'to',\n",
              " 'see',\n",
              " 'it',\n",
              " 'pop',\n",
              " 'down',\n",
              " 'a',\n",
              " 'large',\n",
              " 'rabbit',\n",
              " '-',\n",
              " 'hole',\n",
              " 'under',\n",
              " 'the',\n",
              " 'hedge',\n",
              " '.',\n",
              " 'in',\n",
              " 'another',\n",
              " 'moment',\n",
              " 'down',\n",
              " 'went',\n",
              " 'alice',\n",
              " 'after',\n",
              " 'it',\n",
              " ',',\n",
              " 'never',\n",
              " 'once',\n",
              " 'considering',\n",
              " 'how',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " 'she',\n",
              " 'was',\n",
              " 'to',\n",
              " 'get',\n",
              " 'out',\n",
              " 'again',\n",
              " '.',\n",
              " 'the',\n",
              " 'rabbit',\n",
              " '-',\n",
              " 'hole',\n",
              " 'went',\n",
              " 'straight',\n",
              " 'on',\n",
              " 'like',\n",
              " 'a',\n",
              " 'tunnel',\n",
              " 'for',\n",
              " 'some',\n",
              " 'way',\n",
              " ',',\n",
              " 'and',\n",
              " 'then',\n",
              " 'dipped',\n",
              " 'suddenly',\n",
              " 'down',\n",
              " ',',\n",
              " 'so',\n",
              " 'suddenly',\n",
              " 'that',\n",
              " 'alice',\n",
              " 'had',\n",
              " 'not',\n",
              " 'a',\n",
              " 'moment',\n",
              " 'to',\n",
              " 'think',\n",
              " 'about',\n",
              " 'stopping',\n",
              " 'herself',\n",
              " 'before',\n",
              " 'she',\n",
              " 'found',\n",
              " 'herself',\n",
              " 'falling',\n",
              " 'down',\n",
              " 'a',\n",
              " 'very',\n",
              " 'deep',\n",
              " 'well',\n",
              " '.',\n",
              " 'either',\n",
              " 'the',\n",
              " 'well',\n",
              " 'was',\n",
              " 'very',\n",
              " 'deep',\n",
              " ',',\n",
              " 'or',\n",
              " 'she',\n",
              " 'fell',\n",
              " 'very',\n",
              " 'slowly',\n",
              " ',',\n",
              " 'for',\n",
              " 'she',\n",
              " 'had',\n",
              " 'plenty',\n",
              " 'of',\n",
              " 'time',\n",
              " 'as',\n",
              " 'she',\n",
              " 'went',\n",
              " 'down',\n",
              " 'to',\n",
              " 'look',\n",
              " 'about',\n",
              " 'her',\n",
              " 'and',\n",
              " 'to',\n",
              " 'wonder',\n",
              " 'what',\n",
              " 'was',\n",
              " 'going',\n",
              " 'to',\n",
              " 'happen',\n",
              " 'next',\n",
              " '.',\n",
              " 'first',\n",
              " ',',\n",
              " 'she',\n",
              " 'tried',\n",
              " 'to',\n",
              " 'look',\n",
              " 'down',\n",
              " 'and',\n",
              " 'make',\n",
              " 'out',\n",
              " 'what',\n",
              " 'she',\n",
              " 'was',\n",
              " 'coming',\n",
              " 'to',\n",
              " ',',\n",
              " 'but',\n",
              " 'it',\n",
              " 'was',\n",
              " 'too',\n",
              " 'dark',\n",
              " 'to',\n",
              " 'see',\n",
              " 'anything',\n",
              " ';',\n",
              " 'then',\n",
              " 'she',\n",
              " 'looked',\n",
              " 'at',\n",
              " 'the',\n",
              " 'sides',\n",
              " 'of',\n",
              " 'the',\n",
              " 'well',\n",
              " ',',\n",
              " 'and',\n",
              " 'noticed',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'filled',\n",
              " 'with',\n",
              " 'cupboards',\n",
              " 'and',\n",
              " 'book',\n",
              " '-',\n",
              " 'shelves',\n",
              " ';',\n",
              " 'here',\n",
              " 'and',\n",
              " 'there',\n",
              " 'she',\n",
              " 'saw',\n",
              " 'maps',\n",
              " 'and',\n",
              " 'pictures',\n",
              " 'hung',\n",
              " 'upon',\n",
              " 'pegs',\n",
              " '.',\n",
              " 'she',\n",
              " 'took',\n",
              " 'down',\n",
              " 'a',\n",
              " 'jar',\n",
              " 'from',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'shelves',\n",
              " 'as',\n",
              " 'she',\n",
              " 'passed',\n",
              " ';',\n",
              " 'it',\n",
              " 'was',\n",
              " 'labelled',\n",
              " '\"',\n",
              " 'orange',\n",
              " \"marmalade'\",\n",
              " ',',\n",
              " 'but',\n",
              " 'to',\n",
              " 'her',\n",
              " 'great',\n",
              " 'disappointment',\n",
              " 'it',\n",
              " 'was',\n",
              " 'empty',\n",
              " ':',\n",
              " 'she',\n",
              " 'did',\n",
              " 'not',\n",
              " 'like',\n",
              " 'to',\n",
              " 'drop',\n",
              " 'the',\n",
              " 'jar',\n",
              " 'for',\n",
              " 'fear',\n",
              " 'of',\n",
              " 'killing',\n",
              " 'somebody',\n",
              " ',',\n",
              " 'so',\n",
              " 'managed',\n",
              " 'to',\n",
              " 'put',\n",
              " 'it',\n",
              " 'into',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cupboards',\n",
              " 'as',\n",
              " 'she',\n",
              " 'fell',\n",
              " 'past',\n",
              " 'it',\n",
              " '.',\n",
              " '\"',\n",
              " 'well',\n",
              " '!',\n",
              " '\"',\n",
              " 'thought',\n",
              " 'alice',\n",
              " 'to',\n",
              " 'herself',\n",
              " ',',\n",
              " '\"',\n",
              " 'after',\n",
              " 'such',\n",
              " 'a',\n",
              " 'fall',\n",
              " 'as',\n",
              " 'this',\n",
              " ',',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'think',\n",
              " 'nothing',\n",
              " 'of',\n",
              " 'tumbling',\n",
              " 'down',\n",
              " 'stairs',\n",
              " '!',\n",
              " 'how',\n",
              " 'brave',\n",
              " \"they'll\",\n",
              " 'all',\n",
              " 'think',\n",
              " 'me',\n",
              " 'at',\n",
              " 'home',\n",
              " '!',\n",
              " 'why',\n",
              " ',',\n",
              " 'i',\n",
              " \"wouldn't\",\n",
              " 'say',\n",
              " 'anything',\n",
              " 'about',\n",
              " 'it',\n",
              " ',',\n",
              " 'even',\n",
              " 'if',\n",
              " 'i',\n",
              " 'fell',\n",
              " 'off',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'house',\n",
              " '!',\n",
              " '\"',\n",
              " '(',\n",
              " 'which',\n",
              " 'was',\n",
              " 'very',\n",
              " 'likely',\n",
              " 'true',\n",
              " '.',\n",
              " ')',\n",
              " 'down',\n",
              " ',',\n",
              " 'down',\n",
              " ',',\n",
              " 'down',\n",
              " '.',\n",
              " 'would',\n",
              " 'the',\n",
              " 'fall',\n",
              " 'never',\n",
              " 'come',\n",
              " 'to',\n",
              " 'an',\n",
              " 'end',\n",
              " '!',\n",
              " '\"',\n",
              " 'i',\n",
              " 'wonder',\n",
              " 'how',\n",
              " 'many',\n",
              " 'miles',\n",
              " \"i've\",\n",
              " 'fallen',\n",
              " 'by',\n",
              " 'this',\n",
              " 'time',\n",
              " '?',\n",
              " '\"',\n",
              " 'she',\n",
              " 'said',\n",
              " 'aloud',\n",
              " '.',\n",
              " '\"',\n",
              " 'i',\n",
              " 'must',\n",
              " 'be',\n",
              " 'getting',\n",
              " 'somewhere',\n",
              " 'near',\n",
              " 'the',\n",
              " 'centre',\n",
              " 'of',\n",
              " 'the',\n",
              " 'earth',\n",
              " '.',\n",
              " 'let',\n",
              " 'me',\n",
              " 'see',\n",
              " ':',\n",
              " 'that',\n",
              " 'would',\n",
              " 'be',\n",
              " 'four',\n",
              " 'thousand',\n",
              " 'miles',\n",
              " 'down',\n",
              " ',',\n",
              " 'i',\n",
              " 'think',\n",
              " '-',\n",
              " '-',\n",
              " '\"',\n",
              " '(',\n",
              " 'for',\n",
              " ',',\n",
              " 'you',\n",
              " 'see',\n",
              " ',',\n",
              " 'alice',\n",
              " 'had',\n",
              " 'learnt',\n",
              " 'several',\n",
              " 'things',\n",
              " 'of',\n",
              " 'this',\n",
              " 'sort',\n",
              " 'in',\n",
              " 'her',\n",
              " 'lessons',\n",
              " 'in',\n",
              " 'the',\n",
              " 'schoolroom',\n",
              " ',',\n",
              " 'and',\n",
              " 'though',\n",
              " 'this',\n",
              " 'was',\n",
              " 'not',\n",
              " 'a',\n",
              " 'very',\n",
              " 'good',\n",
              " 'opportunity',\n",
              " 'for',\n",
              " 'showing',\n",
              " 'off',\n",
              " 'her',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'as',\n",
              " 'there',\n",
              " 'was',\n",
              " 'no',\n",
              " 'one',\n",
              " 'to',\n",
              " 'listen',\n",
              " 'to',\n",
              " 'her',\n",
              " ',',\n",
              " 'still',\n",
              " 'it',\n",
              " 'was',\n",
              " 'good',\n",
              " 'practice',\n",
              " 'to',\n",
              " 'say',\n",
              " 'it',\n",
              " 'over',\n",
              " ')',\n",
              " '\"',\n",
              " '-',\n",
              " '-',\n",
              " 'yes',\n",
              " ',',\n",
              " \"that's\",\n",
              " 'about',\n",
              " 'the',\n",
              " 'right',\n",
              " 'distance',\n",
              " '-',\n",
              " '-',\n",
              " 'but',\n",
              " 'then',\n",
              " 'i',\n",
              " 'wonder',\n",
              " 'what',\n",
              " 'latitude',\n",
              " 'or',\n",
              " 'longitude',\n",
              " \"i've\",\n",
              " 'got',\n",
              " 'to',\n",
              " '?',\n",
              " '\"',\n",
              " '(',\n",
              " 'alice',\n",
              " 'had',\n",
              " 'no',\n",
              " 'idea',\n",
              " 'what',\n",
              " 'latitude',\n",
              " 'was',\n",
              " ',',\n",
              " 'or',\n",
              " 'longitude',\n",
              " 'either',\n",
              " ',',\n",
              " 'but',\n",
              " 'thought',\n",
              " 'they',\n",
              " 'were',\n",
              " 'nice',\n",
              " 'grand',\n",
              " 'words',\n",
              " 'to',\n",
              " 'say',\n",
              " '.',\n",
              " ')',\n",
              " 'presently',\n",
              " 'she',\n",
              " 'began',\n",
              " 'again',\n",
              " '.',\n",
              " '\"',\n",
              " 'i',\n",
              " 'wonder',\n",
              " 'if',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'fall',\n",
              " 'right',\n",
              " 'through',\n",
              " 'the',\n",
              " 'earth',\n",
              " '!',\n",
              " 'how',\n",
              " 'funny',\n",
              " \"it'll\",\n",
              " 'seem',\n",
              " 'to',\n",
              " 'come',\n",
              " 'out',\n",
              " 'among',\n",
              " 'the',\n",
              " 'people',\n",
              " 'that',\n",
              " 'walk',\n",
              " 'with',\n",
              " 'their',\n",
              " 'heads',\n",
              " 'downward',\n",
              " '!',\n",
              " 'the',\n",
              " 'antipathies',\n",
              " ',',\n",
              " 'i',\n",
              " 'think',\n",
              " '-',\n",
              " '-',\n",
              " '\"',\n",
              " '(',\n",
              " 'she',\n",
              " 'was',\n",
              " 'rather',\n",
              " 'glad',\n",
              " 'there',\n",
              " 'was',\n",
              " 'no',\n",
              " 'one',\n",
              " 'listening',\n",
              " ',',\n",
              " 'this',\n",
              " 'time',\n",
              " ',',\n",
              " 'as',\n",
              " 'it',\n",
              " \"didn't\",\n",
              " 'sound',\n",
              " 'at',\n",
              " 'all',\n",
              " 'the',\n",
              " 'right',\n",
              " 'word',\n",
              " ')',\n",
              " '\"',\n",
              " '-',\n",
              " '-',\n",
              " 'but',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'have',\n",
              " 'to',\n",
              " 'ask',\n",
              " 'them',\n",
              " 'what',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'the',\n",
              " 'country',\n",
              " 'is',\n",
              " ',',\n",
              " 'you',\n",
              " 'know',\n",
              " '.',\n",
              " 'please',\n",
              " ',',\n",
              " \"ma'am\",\n",
              " ',',\n",
              " 'is',\n",
              " 'this',\n",
              " 'new',\n",
              " 'zealand',\n",
              " 'or',\n",
              " 'australia',\n",
              " '?',\n",
              " '\"',\n",
              " '(',\n",
              " 'and',\n",
              " 'she',\n",
              " 'tried',\n",
              " 'to',\n",
              " 'curtsey',\n",
              " 'as',\n",
              " 'she',\n",
              " 'spoke',\n",
              " '-',\n",
              " '-',\n",
              " 'fancy',\n",
              " 'curtseying',\n",
              " 'as',\n",
              " \"you're\",\n",
              " 'falling',\n",
              " 'through',\n",
              " 'the',\n",
              " 'air',\n",
              " '!',\n",
              " 'do',\n",
              " 'you',\n",
              " 'think',\n",
              " 'you',\n",
              " 'could',\n",
              " 'manage',\n",
              " 'it',\n",
              " '?',\n",
              " ')',\n",
              " '\"',\n",
              " 'and',\n",
              " 'what',\n",
              " 'an',\n",
              " 'ignorant',\n",
              " 'little',\n",
              " 'girl',\n",
              " \"she'll\",\n",
              " 'think',\n",
              " 'me',\n",
              " 'for',\n",
              " 'asking',\n",
              " '!',\n",
              " 'no',\n",
              " ',',\n",
              " \"it'll\",\n",
              " 'never',\n",
              " 'do',\n",
              " 'to',\n",
              " 'ask',\n",
              " ':',\n",
              " 'perhaps',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'see',\n",
              " 'it',\n",
              " 'written',\n",
              " 'up',\n",
              " 'somewhere',\n",
              " '.',\n",
              " '\"',\n",
              " 'down',\n",
              " ',',\n",
              " 'down',\n",
              " ',',\n",
              " 'down',\n",
              " '.',\n",
              " 'there',\n",
              " 'was',\n",
              " 'nothing',\n",
              " 'else',\n",
              " 'to',\n",
              " 'do',\n",
              " ',',\n",
              " 'so',\n",
              " 'alice',\n",
              " 'soon',\n",
              " 'began',\n",
              " 'talking',\n",
              " 'again',\n",
              " '.',\n",
              " '\"',\n",
              " \"dinah'll\",\n",
              " 'miss',\n",
              " 'me',\n",
              " 'very',\n",
              " 'much',\n",
              " 'to',\n",
              " '-',\n",
              " 'night',\n",
              " ',',\n",
              " 'i',\n",
              " 'should',\n",
              " 'think',\n",
              " '!',\n",
              " '\"',\n",
              " '(',\n",
              " 'dinah',\n",
              " 'was',\n",
              " 'the',\n",
              " 'cat',\n",
              " '.',\n",
              " ')',\n",
              " '\"',\n",
              " 'i',\n",
              " 'hope',\n",
              " \"they'll\",\n",
              " 'remember',\n",
              " 'her',\n",
              " 'saucer',\n",
              " 'of',\n",
              " 'milk',\n",
              " 'at',\n",
              " 'tea',\n",
              " '-',\n",
              " 'time',\n",
              " '.',\n",
              " 'dinah',\n",
              " 'my',\n",
              " 'dear',\n",
              " '!',\n",
              " 'i',\n",
              " 'wish',\n",
              " 'you',\n",
              " 'were',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "s7lD9KaOqEZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "960bff03-710c-40ff-a2a2-3f8f1630fb63"
      },
      "cell_type": "code",
      "source": [
        "alice_words[1024]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"that's\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "jSCVVVkEqEZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6b843c0-be72-4ec4-fba0-2937585d2119"
      },
      "cell_type": "code",
      "source": [
        "len(alice_words)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "OnrJqjfNqEZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = set(alice_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1tzeDihqEZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b0b5c30-65c8-44d2-af44-0c202d92613d"
      },
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "v94QG9stqEZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind_to_word = {i: word for i,word in enumerate(vocab)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOCWg-12qEZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_ind = {word: i for i,word in ind_to_word.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YQg_YsriqEaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(s):\n",
        "    chars = string.punctuation\n",
        "    for c in chars:\n",
        "        s = s.replace(c, \" \"+c+\" \")\n",
        "    s = s.lower()\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dMTJaZLqEaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accept(words):\n",
        "    for word in words:\n",
        "        if(not word in vocab):\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WM8RDPUIqEaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abcc5369-8c0c-436a-f702-319105036c77"
      },
      "cell_type": "code",
      "source": [
        "accept([\"alice\"])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "M6k3KxsFqEaN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_ind(s):\n",
        "    s = normalize(s)\n",
        "    s_words = s.split()\n",
        "    if(not accept(s_words)):\n",
        "        print(\"Error\")\n",
        "        return \"\"\n",
        "    return np.array([word_to_ind[word] for word in s_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwKR_BzIqEaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_list_to_ind(s_words):\n",
        "    if(not accept(s_words)):\n",
        "        print(\"Error\")\n",
        "        return \"\"\n",
        "    return np.array([word_to_ind[word] for word in s_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLjBW4uOqEaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "979bbf13-3eb7-419a-e63a-5fdcb525e926"
      },
      "cell_type": "code",
      "source": [
        "text_to_ind(\"Alice in in\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1238,  448,  448])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "z-d_vhEJqEaa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ind_to_text(inds):\n",
        "    s = \"\"\n",
        "    for i in range(inds.shape[0]):\n",
        "        s += ind_to_word[inds[i]] + \" \"\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ac_Ea1ueqEao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47871468-23d8-4b50-bfbf-78c9de0e84b7"
      },
      "cell_type": "code",
      "source": [
        "ind_to_text(text_to_ind(\"Alice, ? land\"))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alice , ? land '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "Jf4h5kFCqEat",
        "colab_type": "code",
        "colab": {},
        "outputId": "7681ef9b-b55a-491d-f420-e590e7540923"
      },
      "cell_type": "code",
      "source": [
        "del(alice_inds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'alice_inds' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-128-1231a1fef6ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malice_inds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'alice_inds' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JrYOf95YqEa1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alice_ind = word_list_to_ind(alice_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9HsGkStqEa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "077ed735-1d0f-4dfd-d6c3-b61261520cca"
      },
      "cell_type": "code",
      "source": [
        "print(alice_ind.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34287,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4eMvc9lqEbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_len = 20\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(alice_ind.shape[0] - sequence_len - 1):\n",
        "    train_x.append(alice_ind[i:i+sequence_len])\n",
        "    train_y.append(alice_ind[i+sequence_len])\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rDvL8WOqEbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31c1e7ac-86b6-4514-86ba-e5fb0807359d"
      },
      "cell_type": "code",
      "source": [
        "train_x.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34266, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "LgFpUtTwqEbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec6ebba0-cba8-4298-fb46-7ddd1e533a72"
      },
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34266,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "UEokTzmCqEbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97a797f2-234f-4f8f-caca-590b7d1ff7f1"
      },
      "cell_type": "code",
      "source": [
        "ind_to_text(train_x[46])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "': once or twice she had peeped into the book her sister was reading , but it had no pictures '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "zE9dNWfaqEbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da6a8bc4-964b-4280-9e27-4cb307de3c77"
      },
      "cell_type": "code",
      "source": [
        "ind_to_text(np.array([train_y[45]]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pictures '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "-kEva-V-qEb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Dense, Embedding, CuDNNLSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eC5mRN4QqEcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Embedding(len(vocab), 30))\n",
        "#model.add(LSTM(32, return_sequences=False))\n",
        "model.add(CuDNNLSTM(128, return_sequences=True)) # 64\n",
        "model.add(CuDNNLSTM(256, return_sequences=False)) #126\n",
        "model.add(Dense(len(vocab), activation = \"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFQx9-kyqEcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "48f4cda5-c794-4327-ce90-d6f8cff4fc69"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 30)          79710     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)    (None, None, 128)         81920     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_13 (CuDNNLSTM)    (None, 256)               395264    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2657)              682849    \n",
            "=================================================================\n",
            "Total params: 1,239,743\n",
            "Trainable params: 1,239,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3IF1bM6VsHHe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = keras.optimizers.Adam(), loss = keras.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtSdjfrNteUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1126
        },
        "outputId": "d21905d7-2238-4f5e-b7d8-343b62dccfbb"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y, batch_size=32, epochs=30)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "34266/34266 [==============================] - 22s 643us/step - loss: 5.6027 - acc: 0.1060\n",
            "Epoch 2/30\n",
            "34266/34266 [==============================] - 21s 616us/step - loss: 5.0837 - acc: 0.1412\n",
            "Epoch 3/30\n",
            "34266/34266 [==============================] - 21s 616us/step - loss: 4.8227 - acc: 0.1643\n",
            "Epoch 4/30\n",
            "34266/34266 [==============================] - 21s 613us/step - loss: 4.5913 - acc: 0.1900\n",
            "Epoch 5/30\n",
            "34266/34266 [==============================] - 21s 611us/step - loss: 4.3992 - acc: 0.2034\n",
            "Epoch 6/30\n",
            "34266/34266 [==============================] - 21s 613us/step - loss: 4.2327 - acc: 0.2149\n",
            "Epoch 7/30\n",
            "34266/34266 [==============================] - 21s 610us/step - loss: 4.0892 - acc: 0.2235\n",
            "Epoch 8/30\n",
            "34266/34266 [==============================] - 21s 608us/step - loss: 3.9443 - acc: 0.2314\n",
            "Epoch 9/30\n",
            "34266/34266 [==============================] - 21s 609us/step - loss: 3.7996 - acc: 0.2395\n",
            "Epoch 10/30\n",
            "34266/34266 [==============================] - 21s 612us/step - loss: 3.6624 - acc: 0.2455\n",
            "Epoch 11/30\n",
            "34266/34266 [==============================] - 21s 610us/step - loss: 3.5296 - acc: 0.2537\n",
            "Epoch 12/30\n",
            "34266/34266 [==============================] - 21s 612us/step - loss: 3.3961 - acc: 0.2633\n",
            "Epoch 13/30\n",
            "34266/34266 [==============================] - 21s 611us/step - loss: 3.2647 - acc: 0.2751\n",
            "Epoch 14/30\n",
            "34266/34266 [==============================] - 21s 610us/step - loss: 3.1328 - acc: 0.2913\n",
            "Epoch 15/30\n",
            "34266/34266 [==============================] - 21s 612us/step - loss: 3.0075 - acc: 0.3071\n",
            "Epoch 16/30\n",
            "34266/34266 [==============================] - 21s 609us/step - loss: 2.8889 - acc: 0.3245\n",
            "Epoch 17/30\n",
            "34266/34266 [==============================] - 21s 612us/step - loss: 2.7681 - acc: 0.3444\n",
            "Epoch 18/30\n",
            "34266/34266 [==============================] - 21s 611us/step - loss: 2.6572 - acc: 0.3665\n",
            "Epoch 19/30\n",
            "34266/34266 [==============================] - 21s 612us/step - loss: 2.5440 - acc: 0.3869\n",
            "Epoch 20/30\n",
            "34266/34266 [==============================] - 21s 610us/step - loss: 2.4385 - acc: 0.4096\n",
            "Epoch 21/30\n",
            "34266/34266 [==============================] - 21s 611us/step - loss: 2.3345 - acc: 0.4293\n",
            "Epoch 22/30\n",
            "34266/34266 [==============================] - 21s 610us/step - loss: 2.2365 - acc: 0.4492\n",
            "Epoch 23/30\n",
            "34266/34266 [==============================] - 21s 602us/step - loss: 2.1350 - acc: 0.4739\n",
            "Epoch 24/30\n",
            "34266/34266 [==============================] - 21s 605us/step - loss: 2.0419 - acc: 0.4937\n",
            "Epoch 25/30\n",
            "34266/34266 [==============================] - 21s 599us/step - loss: 1.9459 - acc: 0.5157\n",
            "Epoch 26/30\n",
            "34266/34266 [==============================] - 20s 589us/step - loss: 1.8573 - acc: 0.5368\n",
            "Epoch 27/30\n",
            "34266/34266 [==============================] - 20s 587us/step - loss: 1.7672 - acc: 0.5587\n",
            "Epoch 28/30\n",
            "34266/34266 [==============================] - 20s 583us/step - loss: 1.6798 - acc: 0.5791\n",
            "Epoch 29/30\n",
            "34266/34266 [==============================] - 20s 581us/step - loss: 1.5904 - acc: 0.6033\n",
            "Epoch 30/30\n",
            "34266/34266 [==============================] - 20s 581us/step - loss: 1.5150 - acc: 0.6226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35472816a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "HA3clA_SuuJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_new = keras.Sequential()\n",
        "model_new.add(Embedding(len(vocab), 30, batch_input_shape=(1, 1)))\n",
        "#model.add(LSTM(32, return_sequences=False))\n",
        "model_new.add(CuDNNLSTM(128, return_sequences=True, stateful = True))\n",
        "model_new.add(CuDNNLSTM(256, return_sequences=False, stateful = True))\n",
        "model_new.add(Dense(len(vocab), activation = \"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UTJjciTKvUu6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_new.set_weights(model.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWnzI71juLXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predictRandom(s, numWords, conf=1):\n",
        "  s_return = s\n",
        "  s_ind = text_to_ind(s)\n",
        "  model_new.reset_states()\n",
        "  \n",
        "  for i in range(s_ind.shape[0]):\n",
        "    pred = model_new.predict_on_batch(np.array(s_ind[i]).reshape(1,1))\n",
        "    \n",
        "  for i in range(numWords):\n",
        "    pred_new = np.power(pred[0], conf)\n",
        "    pred_new = pred_new/np.sum(pred_new)\n",
        "    \n",
        "    next_word_ind = np.random.choice(np.arange(len(vocab)), p = pred_new)\n",
        "    \n",
        "    #next_word_ind = np.argmax(pred)\n",
        "    s_return += \" \" + ind_to_word[next_word_ind]\n",
        "    pred = model_new.predict_on_batch(np.array(next_word_ind).reshape(1,1))\n",
        "  return s_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxqogGXex6Pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fefd9f2a-ac5a-4b92-8da5-e7e504f39684"
      },
      "cell_type": "code",
      "source": [
        "predictRandom(\"How much time is left?\", 15, 3)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How much time is left? \" \" in you , \" said the mock turtle . \" i\\'m a curious'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "ERFBcPYM8Rtr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(s, numWords):\n",
        "  s_return = s\n",
        "  s_ind = text_to_ind(s)\n",
        "  model_new.reset_states()\n",
        "  \n",
        "  for i in range(s_ind.shape[0]):\n",
        "    pred = model_new.predict_on_batch(np.array(s_ind[i]).reshape(1,1))\n",
        "    \n",
        "  for i in range(numWords):\n",
        "    next_word_ind = np.argmax(pred)\n",
        "    s_return += \" \" + ind_to_word[next_word_ind]\n",
        "    pred = model_new.predict_on_batch(np.array(next_word_ind).reshape(1,1))\n",
        "  return s_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0Cf8xZLAfav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJ3XtEujAlzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings = model.get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qGBuXI2AvTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d8ab58f-3b81-4d0b-fb14-983ca2a44121"
      },
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2657, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "metadata": {
        "id": "gTOgXZtjAziY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tsne = TSNE()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCkZvJszA3jw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plane_embs = tsne.fit_transform(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbrX7Zp-CFlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plane_embs.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8WjV3otCIWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pylab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cD6WTQnDCMRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pylab.figure()\n",
        "for i in range(plane_embs.shape[0]):\n",
        "  pylab.annotate(s = ind_to_word[i], xy = (plane_embs.shape[0], plane_embs.shape[1]))\n",
        "pylab.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}